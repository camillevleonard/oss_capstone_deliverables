{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master notebook with other notebook reference and SQL join references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import operator\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "#import pygraphviz\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "#python -m ipykernel install --user --name graphviz_oss --display-name \"graphviz_oss_smn\"\n",
    "import datatable as dt\n",
    "import sidetable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Edgelist Creation\n",
    "* with license and github homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('/project/class/sds_sdad/oss_capstone2021-2022/clean_data_11132021/pypi_meta_with_license_github_slugs.csv',low_memory=False) #read data\n",
    "meta = meta.drop('Unnamed: 0', axis=1) #drop row name column\n",
    "meta['dependency'] = meta['dependency'].apply(lambda x: 'none available' if x is np.NaN else x)\n",
    "meta.name = meta.name.apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "meta['one_dep'] = meta['dependency'].apply(lambda x: x.split(' ')[0].split('=')[0].split('.')[0].split('~')[0].split('>')[0].split('[')[0].split('<')[0].replace(';', ''))\n",
    "dep_df = meta[['name','one_dep']]\n",
    "dep_df.columns = ['name','dependency_name']\n",
    "dep_df = dep_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_df.to_csv('/project/class/sds_sdad/oss_capstone2021-2022/clean_data_11132021/dependency_edgelist_03072022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slugs for packages in dependency edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('/project/class/sds_sdad/oss_capstone2021-2022/clean_data_11132021/pypi_meta_with_license_github_slugs.csv',low_memory=False) #read data\n",
    "meta = meta.drop('Unnamed: 0', axis=1) #drop row name column\n",
    "print(\"Nulls in all columns:\",meta.isnull().sum())\n",
    "print(\"Uniq no dependency packages: \",meta[meta.dependency.isna()==True].name.nunique())\n",
    "#meta['dependency'] = meta['dependency'].apply(lambda x: 'none available' if x is np.NaN else x)\n",
    "meta = meta.apply(lambda x: x.astype(str).str.lower())\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta.name.str.contains('xstatic-term')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta.slug.str.rstrip('/').str.contains('.*/.*/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta.slug.str.contains('.*/.*/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = meta.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[~df.slug.str.contains('.*github.com/')]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with unclean slugs, i.e, filtered on thsoe with github.com in the front\n",
    "df_unclean = df[df.slug.str.contains('.*github.com/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the github.com with \"\"\n",
    "df_unclean.slug = df_unclean.slug.str.replace('.*github.com/', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unclean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat cleaned rows with original filtered df\n",
    "df_clean = pd.concat([df_filtered,df_unclean])\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[df_clean.slug.str[-1]=='/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df to now clean slashes at the end of string by using rstrip\n",
    "df_no_slash = df_clean.copy()\n",
    "df_no_slash.slug = df_no_slash.slug.str.rstrip('//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_slash.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new df with no github.io and slashes at end\n",
    "#(df_no_slash.slug.str.contains('/')) |\n",
    "df_new_slugs = df_no_slash[~( (df_no_slash.slug.str.contains('github.io')) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_slugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filtering out those with single slugs. This is concatenated with single slug \n",
    "(username missing package names) df after fixing it later.\n",
    "'''\n",
    "df_no_single_slug = df_new_slugs[df_new_slugs.slug.str.contains('/')]\n",
    "df_no_single_slug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filter rows with slugs wwhic ahve packagenames but no usernames. \n",
    "This is fixed and later concatenated with proper slugs'''\n",
    "df_single_slugs = df_new_slugs[~df_new_slugs.slug.str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_slugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create slugs for only usernames hopin it will be a slug\n",
    "df_single_slugs.slug = df_single_slugs.slug+'/'+df_single_slugs.name\n",
    "df_single_slugs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_slugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat both df with single slugs fixed and proper slugs\n",
    "df_full_slugs = pd.concat([df_no_single_slug,df_single_slugs])\n",
    "df_full_slugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs = df_full_slugs[['name','slug']]\n",
    "df_full_slugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups = df_full_slugs.drop_duplicates()\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip('\"')\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip('{')\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip('}')\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip('~')\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip(\"'\")\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.rstrip(\"/\")\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip(\"#\")\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.slug = df_full_slugs_no_dups.slug.str.strip(\"*\")\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups = df_full_slugs_no_dups.drop_duplicates()\n",
    "df_full_slugs_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_count = pd.DataFrame(df_full_slugs_no_dups.value_counts()).reset_index()\n",
    "slug_count.columns=['name','slug','count']\n",
    "slug_count[slug_count['count']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_slugs_no_dups[df_full_slugs_no_dups.slug=='smn/django-dirtyfields']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_full_slugs_no_dups.groupby('slug').count()).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv\n",
    "df_full_slugs_no_dups.to_csv('/project/class/sds_sdad/oss_capstone2021-2022/clean_data_11132021/oss_pypi_2021_cleaner_slugs_04022022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making conenction to postgresSQL DB\n",
    "pgpassword = os.getenv('password')\n",
    "pguser = os.getenv('user')\n",
    "host =  'postgis1-s.bii.virginia.edu'\n",
    "database = 'sdad'\n",
    "#port = \n",
    "\n",
    "#trying connection\n",
    "dbserver_p = psycopg2.connect(\n",
    "    user=pguser, \n",
    "    password=pgpassword, \n",
    "    host=host,\n",
    "    database=database \n",
    ")\n",
    "\n",
    "#dbserver_p.autocommit = True\n",
    "cursor_p = dbserver_p.cursor()\n",
    "engine_p = create_engine(\"postgresql+psycopg2://{user}:{pw}@{host}/{db}\"\n",
    "                       .format(user=pguser, pw=pgpassword, host=host, db=database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in a PostgreSQL engine and query and return dataframe\n",
    "def load_db_table(query, eng):\n",
    "    '''\n",
    "    Function which will use connection engine with pd.read_sql_query\n",
    "    '''\n",
    "    data = pd.read_sql_query(query, con=eng)\n",
    "    return data\n",
    "\n",
    "def load_tbl_cur(query, cursor):\n",
    "    '''\n",
    "    Function which will use cursor and fetch all the rows\n",
    "    from result of sql query and convert to pandas dataframe\n",
    "    '''\n",
    "    cursor.execute(query)\n",
    "    df = cursor.fetchall()\n",
    "    colnames = [x[0] for x in cursor.description]\n",
    "    return pd.DataFrame(df, columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a table from cleaned slugs csv 04022022\n",
    "df_full_slugs_no_dups.to_sql('pypi_meta_slug_cleaner_04022022', con = engine_p, \\\n",
    "                     index=False, chunksize=1000, if_exists = 'replace', schema='gh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM gh.pypi_meta_slug_cleaner_04022022\n",
    "where slug is not null\n",
    "'''\n",
    "df_slug_commits = load_db_table(query, engine_p)\n",
    "df_slug_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_slugs_in_cost = df_slug_commits_cost[df_slug_commits_cost.slug.isna()==True].drop_duplicates().slug_meta.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_slugs_in_cost_name = df_slug_commits[df_slug_commits.slug.isin(missing_slugs_in_cost)].name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_slugs_in_cost_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing for number of packages which were created afte 2019 on pypi\n",
    "new_packages = pd.read_csv('pre_2020_gh_package.csv')\n",
    "new_packages.name = new_packages.name.apply(lambda x: str(x).lower())\n",
    "new_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_packages[new_packages.name.isin(missing_slugs_in_cost_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slug_commits[df_slug_commits.name.isin(new_packages.name.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query to save all slug names from sponsors github repo whic hdid nto join with slug_meta\n",
    "query_cost_join = '''\n",
    "select slug_meta from gh.pypi_cost_by_repo_clean_lower_04022022\n",
    "where slug is null\n",
    "\n",
    "'''\n",
    "slug_didnot_join = load_db_table(query_cost_join, engine_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_didnot_join.to_csv('/project/class/sds_sdad/oss_capstone2021-2022/clean_data_11132021/slugs_did_not_join_with_commits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a materialized view for repos and costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join on commits data \n",
    "query_cost_join = '''\n",
    "CREATE MATERIALIZED VIEW gh.pypi_cost_by_repo_clean_lower_04022022_2 \n",
    "    AS (SELECT gh.pypi_meta_slug_cleaner_04022022.slug AS slug_meta, \n",
    "    gh.cost_by_repo_0919_dd_nmrc_jbsc_.* \n",
    "    FROM gh.pypi_meta_slug_cleaner_04022022 \n",
    "    INNER JOIN gh.cost_by_repo_0919_dd_nmrc_jbsc_ \n",
    "    ON \n",
    "    LOWER(gh.pypi_meta_slug_cleaner_04022022.slug)=LOWER(gh.cost_by_repo_0919_dd_nmrc_jbsc_.slug));\n",
    "\n",
    "'''\n",
    "load_db_table(query_cost_join, engine_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM gh.pypi_cost_by_repo_clean_lower_04022022_2\n",
    "'''\n",
    "df_slug_commits_cost = load_db_table(query, engine_p)\n",
    "df_slug_commits_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other sql queries used to create views for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this was converted to a db table pypi_cost_by_repo_clean_lower\n",
    "# gh.commits_dd_nmrc_jbsc_\n",
    "\n",
    "# command used to make table in terminal shell\n",
    "'''\n",
    "CREATE MATERIALIZED VIEW gh.pypi_cost_by_repo_clean_lower_ \n",
    "AS (SELECT gh.pypi_meta_slug_clean.slug AS slug_meta, gh.cost_by_repo_0919_dd_nmrc_jbsc.* \n",
    "FROM gh.pypi_meta_slug_clean \n",
    "LEFT JOIN gh.cost_by_repo_0919_dd_nmrc_jbsc \n",
    "ON LOWER(gh.pypi_meta_slug_clean.slug)=LOWER(gh.cost_by_repo_0919_dd_nmrc_jbsc.slug));'''\n",
    "\n",
    "''' \n",
    "\n",
    "CREATE MATERIALIZED VIEW gh.pypi_cost_by_repo_clean_lower_ \n",
    "        AS (SELECT gh.pypi_meta_slug_clean.slug AS slug_meta, gh.cost_by_repo_0919_dd_nmrc_jbsc_.* \n",
    "        FROM gh.pypi_meta_slug_clean \n",
    "        LEFT JOIN gh.cost_by_repo_0919_dd_nmrc_jbsc_ \n",
    "        ON LOWER(gh.pypi_meta_slug_clean.slug)=LOWER(gh.cost_by_repo_0919_dd_nmrc_jbsc_.slug));\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CREATE MATERIALIZED VIEW gh.pypi_cost_by_repo_clean_lower \n",
    "AS (SELECT gh.pypi_meta_slug_clean.slug AS slug_meta, gh.commits_dd_nmrc_jbsc_.* \n",
    "FROM gh.pypi_meta_slug_clean \n",
    "LEFT JOIN gh.cost_by_repo_0919_dd_nmrc_jbsc \n",
    "ON LOWER(gh.pypi_meta_slug_clean.slug)=LOWER(gh.cost_by_repo_0919_dd_nmrc_jbsc.slug));\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table cost_by_repo_0919_dd_nmrc_jbsc Creation\n",
    "* created using oss_2021_pypi_gh_cost_by_repo.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CREATE MATERIALIZED VIEW gh.cost_by_repo_0919_dd_nmrc_jbsc AS (\n",
    "WITH commits_annual AS (\n",
    "SELECT slug, login, additions, deletions, EXTRACT(YEAR FROM committed_date)::int AS year\n",
    "FROM gh.commits_dd_nmrc_jbsc_\n",
    ")\n",
    "\n",
    "SELECT slug, COUNT(*) AS commits, SUM(additions) AS additions, SUM(deletions) AS deletions,\n",
    "\t\t\t\t\tSUM(additions + deletions) AS sum_adds_dels, SUM(additions - deletions) AS net_adds_dels\n",
    "FROM commits_annual\n",
    "WHERE year > 2008 AND year < 2020\n",
    "GROUP BY slug\n",
    ");\n",
    "--old table 7622930\n",
    "--new table 7840227\n",
    "GRANT ALL PRIVILEGES ON TABLE gh.cost_by_repo_0919_dd_nmrc_jbsc TO ncses_oss;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table for top contributors of a repo\n",
    "* Getting max commits for country selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"\"\"\n",
    "\n",
    "SELECT a.*, b.country \n",
    "FROM(     \n",
    "    SELECT m.slug, m.login, MAX(total_additions + total_deletions) as total_commits\n",
    "    FROM (\n",
    "        SELECT p.slug, c.login,\n",
    "            sum(c.additions) OVER(PARTITION BY p.slug, c.login) AS total_additions,\n",
    "            sum(c.deletions) OVER(PARTITION BY p.slug, c.login) AS total_deletions\n",
    "        FROM gh.pypi_cost_by_repo_clean_lower_04022022_2 as p\n",
    "        INNER JOIN gh.commits_dd_nmrc_jbsc_ as c ON p.slug=c.slug\n",
    "    ) AS m\n",
    "    GROUP BY m.slug, m.login\n",
    "    ORDER BY slug, total_commits DESC\n",
    ") AS a\n",
    "INNER JOIN gh_cost.sectored_fractioned_103121 as b ON a.login = b.login\n",
    "\n",
    "\"\"\"\n",
    "pkg_cost_tbl = load_db_table(myquery,engine_p)\n",
    "\n",
    "# have yet to figure out how to filter to only the login with max commits but can do it in python \n",
    "pkg_cost_tbl = pkg_cost_tbl.dropna()\n",
    "pkg_cost_tbl_max = pkg_cost_tbl.groupby(['slug'])['total_commits'].max()\n",
    "pkg_cost_tbl_max = pd.DataFrame(pkg_cost_tbl_max).reset_index().merge(pkg_cost_tbl, on=['slug', 'total_commits'])\n",
    "pkg_cost_tbl_max.to_csv('max_contrib_country_per_package.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other notebook references\n",
    "* temp_meta_1 -> temp_meta_creation.ipynb\n",
    "* Dependency Edgelist - oss_2021_pypi_dependency_edgelist\n",
    "* Contributor network edge list- oss_2021_pypi_contributors_join_11202021.sql \n",
    "* Cleaning slugs - oss_pypi_2021_meta_cleaning_slugs_02122022.ipynb\n",
    "* cost_by_repo_0919_dd_nmrc_jbsc - oss_2021_pypi_gh_cost_by_repo.sql\n",
    "* downloads - oss_2021_meta_download_EDA\n",
    "* sector stuff - oss_2021_sector_download_EDA.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
